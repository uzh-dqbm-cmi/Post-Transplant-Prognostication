{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b0d543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T11:41:01.628105Z",
     "start_time": "2025-02-01T11:40:34.086512Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "from typing import Dict, List, Tuple\n",
    "from scipy import stats\n",
    "from utisl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c396f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T11:41:02.273773Z",
     "start_time": "2025-02-01T11:41:01.644595Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"LGBM\"\n",
    "all_predictions = pd.read_csv(\n",
    "    f\"results/next_year_prediction_results_{model_name}_followup_calibrated.csv\",\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "(\n",
    "    data,\n",
    "    baseline_data,\n",
    "    baseline_data_cont,\n",
    "    follow_up_predictors_total,\n",
    "    follow_up_predictors_vars_by_year,\n",
    "    follow_up_predictors_cont,\n",
    ") = data_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8ece21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T11:44:46.300951Z",
     "start_time": "2025-02-01T11:41:02.275776Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Results for death - Y1\n",
      "==================================================\n",
      "\n",
      "--- Multiple Recall Targets ---\n",
      " Recall_Target  Threshold_Found  Actual_Recall  Precision  Specificity     F1    BAC  ROC_AUC  PR_AUC\n",
      "           0.5           0.0250         0.5048     0.0449       0.7125 0.0825 0.6086   0.6558  0.0447\n",
      "           0.6           0.0207         0.6000     0.0427       0.6401 0.0798 0.6200   0.6558  0.0447\n",
      "           0.7           0.0165         0.7048     0.0395       0.5406 0.0747 0.6227   0.6558  0.0447\n",
      "           0.8           0.0121         0.8000     0.0345       0.4003 0.0661 0.6001   0.6558  0.0447\n",
      "           0.9           0.0092         0.9048     0.0319       0.2645 0.0616 0.5847   0.6558  0.0447\n",
      "\n",
      "Single Threshold for 60.0% recall:\n",
      "Found threshold = 0.0207\n",
      "\n",
      "Threshold Metrics:\n",
      "------------------------------\n",
      "True Positives            63.0000\n",
      "True Negatives            2509.0000\n",
      "False Positives           1411.0000\n",
      "False Negatives           42.0000\n",
      "Sensitivity/Recall        0.6000\n",
      "Specificity               0.6401\n",
      "Precision/PPV             0.0427\n",
      "NPV                       0.9835\n",
      "F1 Score                  0.0798\n",
      "BAC                       0.6200\n",
      "\n",
      "Probability Metrics:\n",
      "------------------------------\n",
      "ROC AUC                   0.6558\n",
      "PR AUC                    0.0447\n",
      "\n",
      "Additional Metrics:\n",
      "------------------------------\n",
      "Positive Rate             0.3662\n",
      "Negative Rate             0.6338\n",
      "False Discovery Rate      0.9573\n",
      "False Omission Rate       0.0165\n",
      "\n",
      "--- Multiple Operating Thresholds (Fixed Probability) ---\n",
      " Threshold  TP   FP   TN  FN  Recall  Specificity  Precision    NPV     F1    BAC  ROC_AUC  PR_AUC  PosRate\n",
      "      0.01  90 2722 1198  15  0.8571       0.3056     0.0320 0.9876 0.0617 0.5814   0.6558  0.0447   0.6986\n",
      "      0.02  65 1471 2449  40  0.6190       0.6247     0.0423 0.9839 0.0792 0.6219   0.6558  0.0447   0.3816\n",
      "      0.05  18  353 3567  87  0.1714       0.9099     0.0485 0.9762 0.0756 0.5407   0.6558  0.0447   0.0922\n",
      "      0.10   3   70 3850 102  0.0286       0.9821     0.0411 0.9742 0.0337 0.5054   0.6558  0.0447   0.0181\n",
      "      0.20   0    3 3917 105  0.0000       0.9992     0.0000 0.9739 0.0000 0.4996   0.6558  0.0447   0.0007\n",
      "      0.30   0    0 3920 105  0.0000       1.0000     0.0000 0.9739 0.0000 0.5000   0.6558  0.0447   0.0000\n",
      "      0.50   0    0 3920 105  0.0000       1.0000     0.0000 0.9739 0.0000 0.5000   0.6558  0.0447   0.0000\n",
      "\n",
      "--- Decision Curve Analysis ---\n",
      " threshold  net_benefit_model  net_benefit_treat_all  net_benefit_treat_none\n",
      "      0.05            -0.0001                -0.0252                       0\n",
      "      0.10            -0.0012                -0.0821                       0\n",
      "      0.15            -0.0004                -0.1458                       0\n",
      "      0.20            -0.0002                -0.2174                       0\n",
      "      0.25             0.0000                -0.2986                       0\n",
      "      0.30             0.0000                -0.3913                       0\n",
      "      0.35             0.0000                -0.4983                       0\n",
      "      0.40             0.0000                -0.6232                       0\n",
      "      0.45             0.0000                -0.7708                       0\n",
      "      0.50             0.0000                -0.9478                       0\n",
      "      0.55             0.0000                -1.1643                       0\n",
      "      0.60             0.0000                -1.4348                       0\n",
      "      0.65             0.0000                -1.7826                       0\n",
      "      0.70             0.0000                -2.2464                       0\n",
      "      0.75             0.0000                -2.8957                       0\n",
      "      0.80             0.0000                -3.8696                       0\n",
      "      0.85             0.0000                -5.4928                       0\n",
      "      0.90             0.0000                -8.7391                       0\n",
      "      0.95             0.0000               -18.4783                       0\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 5%) ---\n",
      "Subset              : Top 5.0% (N=202)\n",
      "Precision_top       : 0.0545\n",
      "Recall_top          : 0.1048\n",
      "Subset_size         : 202\n",
      "Total_positives     : 105.0000\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 10%) ---\n",
      "Subset              : Top 10.0% (N=403)\n",
      "Precision_top       : 0.0447\n",
      "Recall_top          : 0.1714\n",
      "Subset_size         : 403\n",
      "Total_positives     : 105.0000\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 20%) ---\n",
      "Subset              : Top 20.0% (N=805)\n",
      "Precision_top       : 0.0497\n",
      "Recall_top          : 0.3810\n",
      "Subset_size         : 805\n",
      "Total_positives     : 105.0000\n",
      "\n",
      "==================================================\n",
      "Results for death - Y2+\n",
      "==================================================\n",
      "\n",
      "--- Multiple Recall Targets ---\n",
      " Recall_Target  Threshold_Found  Actual_Recall  Precision  Specificity     F1    BAC  ROC_AUC  PR_AUC\n",
      "           0.5           0.0512         0.5008     0.1102       0.8838 0.1807 0.6923    0.799   0.123\n",
      "           0.6           0.0386         0.6000     0.0878       0.8207 0.1531 0.7103    0.799   0.123\n",
      "           0.7           0.0293         0.7008     0.0725       0.7424 0.1315 0.7216    0.799   0.123\n",
      "           0.8           0.0216         0.8000     0.0597       0.6375 0.1110 0.7188    0.799   0.123\n",
      "           0.9           0.0156         0.9008     0.0508       0.5164 0.0962 0.7086    0.799   0.123\n",
      "\n",
      "Single Threshold for 60.0% recall:\n",
      "Found threshold = 0.0386\n",
      "\n",
      "Threshold Metrics:\n",
      "------------------------------\n",
      "True Positives            357.0000\n",
      "True Negatives            16986.0000\n",
      "False Positives           3711.0000\n",
      "False Negatives           238.0000\n",
      "Sensitivity/Recall        0.6000\n",
      "Specificity               0.8207\n",
      "Precision/PPV             0.0878\n",
      "NPV                       0.9862\n",
      "F1 Score                  0.1531\n",
      "BAC                       0.7103\n",
      "\n",
      "Probability Metrics:\n",
      "------------------------------\n",
      "ROC AUC                   0.7990\n",
      "PR AUC                    0.1230\n",
      "\n",
      "Additional Metrics:\n",
      "------------------------------\n",
      "Positive Rate             0.1911\n",
      "Negative Rate             0.8089\n",
      "False Discovery Rate      0.9122\n",
      "False Omission Rate       0.0138\n",
      "\n",
      "--- Multiple Operating Thresholds (Fixed Probability) ---\n",
      " Threshold  TP    FP    TN  FN  Recall  Specificity  Precision    NPV     F1    BAC  ROC_AUC  PR_AUC  PosRate\n",
      "      0.01 562 13364  7333  33  0.9445       0.3543     0.0404 0.9955 0.0774 0.6494    0.799   0.123   0.6540\n",
      "      0.02 493  8117 12580 102  0.8286       0.6078     0.0573 0.9920 0.1071 0.7182    0.799   0.123   0.4044\n",
      "      0.05 302  2499 18198 293  0.5076       0.8793     0.1078 0.9842 0.1779 0.6934    0.799   0.123   0.1316\n",
      "      0.10 147   702 19995 448  0.2471       0.9661     0.1731 0.9781 0.2036 0.6066    0.799   0.123   0.0399\n",
      "      0.20  40   141 20556 555  0.0672       0.9932     0.2210 0.9737 0.1031 0.5302    0.799   0.123   0.0085\n",
      "      0.30  16    34 20663 579  0.0269       0.9984     0.3200 0.9727 0.0496 0.5126    0.799   0.123   0.0023\n",
      "      0.50   0     4 20693 595  0.0000       0.9998     0.0000 0.9720 0.0000 0.4999    0.799   0.123   0.0002\n",
      "\n",
      "--- Decision Curve Analysis ---\n",
      " threshold  net_benefit_model  net_benefit_treat_all  net_benefit_treat_none\n",
      "      0.05             0.0080                -0.0232                       0\n",
      "      0.10             0.0032                -0.0801                       0\n",
      "      0.15             0.0014                -0.1436                       0\n",
      "      0.20             0.0002                -0.2151                       0\n",
      "      0.25             0.0000                -0.2961                       0\n",
      "      0.30             0.0001                -0.3887                       0\n",
      "      0.35             0.0000                -0.4955                       0\n",
      "      0.40            -0.0002                -0.6201                       0\n",
      "      0.45            -0.0002                -0.7674                       0\n",
      "      0.50            -0.0002                -0.9441                       0\n",
      "      0.55            -0.0001                -1.1601                       0\n",
      "      0.60             0.0000                -1.4301                       0\n",
      "      0.65             0.0000                -1.7773                       0\n",
      "      0.70             0.0000                -2.2402                       0\n",
      "      0.75             0.0000                -2.8882                       0\n",
      "      0.80             0.0000                -3.8603                       0\n",
      "      0.85             0.0000                -5.4804                       0\n",
      "      0.90             0.0000                -8.7206                       0\n",
      "      0.95             0.0000               -18.4411                       0\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 5%) ---\n",
      "Subset              : Top 5.0% (N=1065)\n",
      "Precision_top       : 0.1568\n",
      "Recall_top          : 0.2807\n",
      "Subset_size         : 1065\n",
      "Total_positives     : 595.0000\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 10%) ---\n",
      "Subset              : Top 10.0% (N=2130)\n",
      "Precision_top       : 0.1183\n",
      "Recall_top          : 0.4235\n",
      "Subset_size         : 2130\n",
      "Total_positives     : 595.0000\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 20%) ---\n",
      "Subset              : Top 20.0% (N=4259)\n",
      "Precision_top       : 0.0850\n",
      "Recall_top          : 0.6084\n",
      "Subset_size         : 4259\n",
      "Total_positives     : 595.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Results for graft_loss - Y1\n",
      "==================================================\n",
      "\n",
      "--- Multiple Recall Targets ---\n",
      " Recall_Target  Threshold_Found  Actual_Recall  Precision  Specificity     F1    BAC  ROC_AUC  PR_AUC\n",
      "           0.5           0.0448         0.5031     0.0813       0.7588 0.1399 0.6309   0.6855  0.0912\n",
      "           0.6           0.0429         0.6012     0.0763       0.6914 0.1355 0.6463   0.6855  0.0912\n",
      "           0.7           0.0403         0.7055     0.0682       0.5915 0.1245 0.6485   0.6855  0.0912\n",
      "           0.8           0.0366         0.8037     0.0570       0.4356 0.1064 0.6196   0.6855  0.0912\n",
      "           0.9           0.0318         0.9018     0.0490       0.2571 0.0929 0.5795   0.6855  0.0912\n",
      "\n",
      "Single Threshold for 60.0% recall:\n",
      "Found threshold = 0.0429\n",
      "\n",
      "Threshold Metrics:\n",
      "------------------------------\n",
      "True Positives            98.0000\n",
      "True Negatives            2657.0000\n",
      "False Positives           1186.0000\n",
      "False Negatives           65.0000\n",
      "Sensitivity/Recall        0.6012\n",
      "Specificity               0.6914\n",
      "Precision/PPV             0.0763\n",
      "NPV                       0.9761\n",
      "F1 Score                  0.1355\n",
      "BAC                       0.6463\n",
      "\n",
      "Probability Metrics:\n",
      "------------------------------\n",
      "ROC AUC                   0.6855\n",
      "PR AUC                    0.0912\n",
      "\n",
      "Additional Metrics:\n",
      "------------------------------\n",
      "Positive Rate             0.3205\n",
      "Negative Rate             0.6795\n",
      "False Discovery Rate      0.9237\n",
      "False Omission Rate       0.0239\n",
      "\n",
      "--- Multiple Operating Thresholds (Fixed Probability) ---\n",
      " Threshold  TP   FP   TN  FN  Recall  Specificity  Precision    NPV     F1    BAC  ROC_AUC  PR_AUC  PosRate\n",
      "      0.01 163 3843    0   0  1.0000       0.0000     0.0407 0.0000 0.0782 0.5000   0.6855  0.0912   1.0000\n",
      "      0.02 163 3843    0   0  1.0000       0.0000     0.0407 0.0000 0.0782 0.5000   0.6855  0.0912   1.0000\n",
      "      0.05  48  478 3365 115  0.2945       0.8756     0.0913 0.9670 0.1393 0.5850   0.6855  0.0912   0.1313\n",
      "      0.10   6   22 3821 157  0.0368       0.9943     0.2143 0.9605 0.0628 0.5155   0.6855  0.0912   0.0070\n",
      "      0.20   0    0 3843 163  0.0000       1.0000     0.0000 0.9593 0.0000 0.5000   0.6855  0.0912   0.0000\n",
      "      0.30   0    0 3843 163  0.0000       1.0000     0.0000 0.9593 0.0000 0.5000   0.6855  0.0912   0.0000\n",
      "      0.50   0    0 3843 163  0.0000       1.0000     0.0000 0.9593 0.0000 0.5000   0.6855  0.0912   0.0000\n",
      "\n",
      "--- Decision Curve Analysis ---\n",
      " threshold  net_benefit_model  net_benefit_treat_all  net_benefit_treat_none\n",
      "      0.05             0.0057                -0.0098                       0\n",
      "      0.10             0.0009                -0.0659                       0\n",
      "      0.15            -0.0001                -0.1286                       0\n",
      "      0.20             0.0000                -0.1991                       0\n",
      "      0.25             0.0000                -0.2791                       0\n",
      "      0.30             0.0000                -0.3704                       0\n",
      "      0.35             0.0000                -0.4759                       0\n",
      "      0.40             0.0000                -0.5989                       0\n",
      "      0.45             0.0000                -0.7442                       0\n",
      "      0.50             0.0000                -0.9186                       0\n",
      "      0.55             0.0000                -1.1318                       0\n",
      "      0.60             0.0000                -1.3983                       0\n",
      "      0.65             0.0000                -1.7409                       0\n",
      "      0.70             0.0000                -2.1977                       0\n",
      "      0.75             0.0000                -2.8372                       0\n",
      "      0.80             0.0000                -3.7966                       0\n",
      "      0.85             0.0000                -5.3954                       0\n",
      "      0.90             0.0000                -8.5931                       0\n",
      "      0.95             0.0000               -18.1862                       0\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 5%) ---\n",
      "Subset              : Top 5.0% (N=201)\n",
      "Precision_top       : 0.1244\n",
      "Recall_top          : 0.1534\n",
      "Subset_size         : 201\n",
      "Total_positives     : 163.0000\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 10%) ---\n",
      "Subset              : Top 10.0% (N=401)\n",
      "Precision_top       : 0.0973\n",
      "Recall_top          : 0.2393\n",
      "Subset_size         : 401\n",
      "Total_positives     : 163.0000\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 20%) ---\n",
      "Subset              : Top 20.0% (N=802)\n",
      "Precision_top       : 0.0848\n",
      "Recall_top          : 0.4172\n",
      "Subset_size         : 802\n",
      "Total_positives     : 163.0000\n",
      "\n",
      "==================================================\n",
      "Results for graft_loss - Y2+\n",
      "==================================================\n",
      "\n",
      "--- Multiple Recall Targets ---\n",
      " Recall_Target  Threshold_Found  Actual_Recall  Precision  Specificity     F1    BAC  ROC_AUC  PR_AUC\n",
      "           0.5           0.0559         0.5017     0.2327       0.9750 0.3179 0.7383   0.8934  0.2653\n",
      "           0.6           0.0320         0.6013     0.1612       0.9526 0.2542 0.7770   0.8934  0.2653\n",
      "           0.7           0.0215         0.7010     0.0997       0.9042 0.1746 0.8026   0.8934  0.2653\n",
      "           0.8           0.0147         0.8007     0.0562       0.7963 0.1050 0.7985   0.8934  0.2653\n",
      "           0.9           0.0087         0.9003     0.0383       0.6577 0.0735 0.7790   0.8934  0.2653\n",
      "\n",
      "Single Threshold for 60.0% recall:\n",
      "Found threshold = 0.0320\n",
      "\n",
      "Threshold Metrics:\n",
      "------------------------------\n",
      "True Positives            181.0000\n",
      "True Negatives            18939.0000\n",
      "False Positives           942.0000\n",
      "False Negatives           120.0000\n",
      "Sensitivity/Recall        0.6013\n",
      "Specificity               0.9526\n",
      "Precision/PPV             0.1612\n",
      "NPV                       0.9937\n",
      "F1 Score                  0.2542\n",
      "BAC                       0.7770\n",
      "\n",
      "Probability Metrics:\n",
      "------------------------------\n",
      "ROC AUC                   0.8934\n",
      "PR AUC                    0.2653\n",
      "\n",
      "Additional Metrics:\n",
      "------------------------------\n",
      "Positive Rate             0.0556\n",
      "Negative Rate             0.9444\n",
      "False Discovery Rate      0.8388\n",
      "False Omission Rate       0.0063\n",
      "\n",
      "--- Multiple Operating Thresholds (Fixed Probability) ---\n",
      " Threshold  TP   FP    TN  FN  Recall  Specificity  Precision    NPV     F1    BAC  ROC_AUC  PR_AUC  PosRate\n",
      "      0.01 266 6293 13588  35  0.8837       0.6835     0.0406 0.9974 0.0776 0.7836   0.8934  0.2653   0.3250\n",
      "      0.02 219 2265 17616  82  0.7276       0.8861     0.0882 0.9954 0.1573 0.8068   0.8934  0.2653   0.1231\n",
      "      0.05 158  559 19322 143  0.5249       0.9719     0.2204 0.9927 0.3104 0.7484   0.8934  0.2653   0.0355\n",
      "      0.10 122  257 19624 179  0.4053       0.9871     0.3219 0.9910 0.3588 0.6962   0.8934  0.2653   0.0188\n",
      "      0.20  70  100 19781 231  0.2326       0.9950     0.4118 0.9885 0.2972 0.6138   0.8934  0.2653   0.0084\n",
      "      0.30  41   30 19851 260  0.1362       0.9985     0.5775 0.9871 0.2204 0.5674   0.8934  0.2653   0.0035\n",
      "      0.50   7    2 19879 294  0.0233       0.9999     0.7778 0.9854 0.0452 0.5116   0.8934  0.2653   0.0004\n",
      "\n",
      "--- Decision Curve Analysis ---\n",
      " threshold  net_benefit_model  net_benefit_treat_all  net_benefit_treat_none\n",
      "      0.05             0.0064                -0.0369                       0\n",
      "      0.10             0.0046                -0.0945                       0\n",
      "      0.15             0.0028                -0.1589                       0\n",
      "      0.20             0.0022                -0.2314                       0\n",
      "      0.25             0.0018                -0.3134                       0\n",
      "      0.30             0.0014                -0.4073                       0\n",
      "      0.35             0.0011                -0.5155                       0\n",
      "      0.40             0.0004                -0.6418                       0\n",
      "      0.45             0.0002                -0.7911                       0\n",
      "      0.50             0.0002                -0.9702                       0\n",
      "      0.55             0.0000                -1.1891                       0\n",
      "      0.60             0.0000                -1.4627                       0\n",
      "      0.65             0.0000                -1.8145                       0\n",
      "      0.70             0.0000                -2.2836                       0\n",
      "      0.75             0.0000                -2.9403                       0\n",
      "      0.80             0.0000                -3.9254                       0\n",
      "      0.85             0.0000                -5.5672                       0\n",
      "      0.90             0.0000                -8.8509                       0\n",
      "      0.95             0.0000               -18.7017                       0\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 5%) ---\n",
      "Subset              : Top 5.0% (N=1010)\n",
      "Precision_top       : 0.1743\n",
      "Recall_top          : 0.5847\n",
      "Subset_size         : 1010\n",
      "Total_positives     : 301.0000\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 10%) ---\n",
      "Subset              : Top 10.0% (N=2019)\n",
      "Precision_top       : 0.1030\n",
      "Recall_top          : 0.6910\n",
      "Subset_size         : 2019\n",
      "Total_positives     : 301.0000\n",
      "\n",
      "--- Top-Fraction Approach (e.g., Top 20%) ---\n",
      "Subset              : Top 20.0% (N=4037)\n",
      "Precision_top       : 0.0585\n",
      "Recall_top          : 0.7841\n",
      "Subset_size         : 4037\n",
      "Total_positives     : 301.0000\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_prob):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive binary classification metrics.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels (after threshold)\n",
    "        y_prob: Prediction probabilities\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing all metrics\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    metrics = {\n",
    "        \"Threshold Metrics\": {\n",
    "            \"True Positives\": int(tp),\n",
    "            \"True Negatives\": int(tn),\n",
    "            \"False Positives\": int(fp),\n",
    "            \"False Negatives\": int(fn),\n",
    "            \"Sensitivity/Recall\": recall_score(y_true, y_pred),\n",
    "            \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "            \"Precision/PPV\": precision_score(y_true, y_pred) if (tp + fp) > 0 else 0,\n",
    "            \"NPV\": tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "            \"F1 Score\": f1_score(y_true, y_pred),\n",
    "            \"BAC\": balanced_accuracy_score(y_true, y_pred),\n",
    "        },\n",
    "        \"Probability Metrics\": {\n",
    "            \"ROC AUC\": roc_auc_score(y_true, y_prob)\n",
    "            if len(np.unique(y_true)) > 1\n",
    "            else np.nan,\n",
    "            \"PR AUC\": average_precision_score(y_true, y_prob),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Additional metrics\n",
    "    metrics[\"Additional Metrics\"] = {\n",
    "        \"Positive Rate\": (tp + fp) / (tp + fp + tn + fn),\n",
    "        \"Negative Rate\": (tn + fn) / (tp + fp + tn + fn),\n",
    "        \"False Discovery Rate\": fp / (fp + tp) if (fp + tp) > 0 else 0,\n",
    "        \"False Omission Rate\": fn / (fn + tn) if (fn + tn) > 0 else 0,\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def find_threshold_for_recall(probs, labels, target_recall=0.80):\n",
    "    \"\"\"\n",
    "    Find the probability threshold that achieves the target recall.\n",
    "    \"\"\"\n",
    "    sorted_indices = np.argsort(probs)[::-1]\n",
    "    sorted_probs = probs[sorted_indices]\n",
    "    sorted_labels = labels[sorted_indices]\n",
    "\n",
    "    unique_probs = np.unique(sorted_probs)[::-1]\n",
    "    for threshold in unique_probs:\n",
    "        pred = (sorted_probs >= threshold).astype(int)\n",
    "        recall = recall_score(sorted_labels, pred)\n",
    "        if recall >= target_recall:\n",
    "            return threshold\n",
    "\n",
    "    return min(unique_probs)\n",
    "\n",
    "\n",
    "def analyze_multiple_recalls(labels, probs, recall_targets):\n",
    "    \"\"\"\n",
    "    For each recall target in recall_targets, find the threshold, make predictions,\n",
    "    and compute metrics. Returns a DataFrame with results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for r in recall_targets:\n",
    "        threshold = find_threshold_for_recall(probs, labels, target_recall=r)\n",
    "        pred = (probs >= threshold).astype(int)\n",
    "        metric_dict = calculate_metrics(labels, pred, probs)\n",
    "        row = {\n",
    "            \"Recall_Target\": r,\n",
    "            \"Threshold_Found\": threshold,\n",
    "            \"Actual_Recall\": metric_dict[\"Threshold Metrics\"][\"Sensitivity/Recall\"],\n",
    "            \"Precision\": metric_dict[\"Threshold Metrics\"][\"Precision/PPV\"],\n",
    "            \"Specificity\": metric_dict[\"Threshold Metrics\"][\"Specificity\"],\n",
    "            \"F1\": metric_dict[\"Threshold Metrics\"][\"F1 Score\"],\n",
    "            \"BAC\": metric_dict[\"Threshold Metrics\"][\"BAC\"],\n",
    "            \"ROC_AUC\": metric_dict[\"Probability Metrics\"][\"ROC AUC\"],\n",
    "            \"PR_AUC\": metric_dict[\"Probability Metrics\"][\"PR AUC\"],\n",
    "        }\n",
    "        results.append(row)\n",
    "\n",
    "    df_multi_recalls = pd.DataFrame(results)\n",
    "    return df_multi_recalls\n",
    "\n",
    "\n",
    "def decision_curve_analysis(labels, probs, thresholds):\n",
    "    \"\"\"\n",
    "    Calculate net benefit across a list of threshold probabilities\n",
    "    for decision curve analysis.\n",
    "\n",
    "    Net Benefit = (TP/N) - (FP/N)*(p_t/(1-p_t))\n",
    "    Treat All => NB = prevalence - (1-prevalence)*(p_t/(1-p_t))\n",
    "    Treat None => NB = 0\n",
    "\n",
    "    Returns a DataFrame with columns: threshold, net_benefit_model,\n",
    "    net_benefit_treat_all, net_benefit_treat_none.\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0.0, 1.0, 21)  # e.g. 0.0, 0.05, ..., 1.0\n",
    "    n = len(labels)\n",
    "    prevalence = np.mean(labels)\n",
    "\n",
    "    results = []\n",
    "    for pt in thresholds:\n",
    "        if pt == 0 or pt == 1:\n",
    "            # Avoid dividing by zero in the formula (or we define net benefit in a special way)\n",
    "            continue\n",
    "\n",
    "        # Predictions at this threshold\n",
    "        pred = (probs >= pt).astype(int)\n",
    "        tp = np.sum((pred == 1) & (labels == 1))\n",
    "        fp = np.sum((pred == 1) & (labels == 0))\n",
    "\n",
    "        nb_model = (tp / n) - (fp / n) * (pt / (1 - pt))\n",
    "        # Treat All => net benefit\n",
    "        nb_treat_all = (prevalence) - ((1 - prevalence) * (pt / (1 - pt)))\n",
    "        # Treat None => 0\n",
    "        nb_treat_none = 0\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"threshold\": pt,\n",
    "                \"tp\": tp,\n",
    "                \"fp\": fp,\n",
    "                \"net_benefit_model\": nb_model,\n",
    "                \"net_benefit_treat_all\": nb_treat_all,\n",
    "                \"net_benefit_treat_none\": nb_treat_none,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def evaluate_multiple_thresholds(labels, probs, thresholds=None):\n",
    "    \"\"\"\n",
    "    Evaluate metrics at multiple operating thresholds (via fixed probability threshold).\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "\n",
    "    results = []\n",
    "    for thr in thresholds:\n",
    "        preds = (probs >= thr).astype(int)\n",
    "        metric_dict = calculate_metrics(labels, preds, probs)\n",
    "        metric_dict[\"threshold\"] = thr\n",
    "        results.append(metric_dict)\n",
    "\n",
    "    records = []\n",
    "    for r in results:\n",
    "        row = {\n",
    "            \"Threshold\": r[\"threshold\"],\n",
    "            \"TP\": r[\"Threshold Metrics\"][\"True Positives\"],\n",
    "            \"FP\": r[\"Threshold Metrics\"][\"False Positives\"],\n",
    "            \"TN\": r[\"Threshold Metrics\"][\"True Negatives\"],\n",
    "            \"FN\": r[\"Threshold Metrics\"][\"False Negatives\"],\n",
    "            \"Recall\": r[\"Threshold Metrics\"][\"Sensitivity/Recall\"],\n",
    "            \"Specificity\": r[\"Threshold Metrics\"][\"Specificity\"],\n",
    "            \"Precision\": r[\"Threshold Metrics\"][\"Precision/PPV\"],\n",
    "            \"NPV\": r[\"Threshold Metrics\"][\"NPV\"],\n",
    "            \"F1\": r[\"Threshold Metrics\"][\"F1 Score\"],\n",
    "            \"BAC\": r[\"Threshold Metrics\"][\"BAC\"],\n",
    "            \"ROC_AUC\": r[\"Probability Metrics\"][\"ROC AUC\"],\n",
    "            \"PR_AUC\": r[\"Probability Metrics\"][\"PR AUC\"],\n",
    "            \"PosRate\": r[\"Additional Metrics\"][\"Positive Rate\"],\n",
    "        }\n",
    "        records.append(row)\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def evaluate_top_k(labels, probs, k=None, fraction=None):\n",
    "    \"\"\"\n",
    "    Evaluate precision and recall in the top-k or top fraction of predicted risks.\n",
    "    \"\"\"\n",
    "    df_temp = pd.DataFrame({\"label\": labels, \"prob\": probs})\n",
    "    df_temp.sort_values(\"prob\", ascending=False, inplace=True)\n",
    "\n",
    "    n_total = len(df_temp)\n",
    "    n_positives = df_temp[\"label\"].sum()\n",
    "\n",
    "    if fraction is not None:\n",
    "        top_n = int(np.ceil(fraction * n_total))\n",
    "        subset = df_temp.head(top_n)\n",
    "        descriptor = f\"Top {fraction*100:.1f}% (N={top_n})\"\n",
    "    elif k is not None:\n",
    "        top_n = min(k, n_total)\n",
    "        subset = df_temp.head(top_n)\n",
    "        descriptor = f\"Top K={k} (N={top_n})\"\n",
    "    else:\n",
    "        raise ValueError(\"Either 'k' or 'fraction' must be specified.\")\n",
    "\n",
    "    n_true_positives = subset[\"label\"].sum()\n",
    "    precision_top = n_true_positives / len(subset) if len(subset) > 0 else 0\n",
    "    recall_top = n_true_positives / n_positives if n_positives > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"Subset\": descriptor,\n",
    "        \"Precision_top\": precision_top,\n",
    "        \"Recall_top\": recall_top,\n",
    "        \"Subset_size\": len(subset),\n",
    "        \"Total_positives\": n_positives,\n",
    "    }\n",
    "\n",
    "\n",
    "#######################################\n",
    "# MAIN ANALYSIS LOGIC\n",
    "#######################################\n",
    "\n",
    "\n",
    "def analyze_predictions(df, outcome_type, year_type, recall_targets):\n",
    "    \"\"\"\n",
    "    Analyze predictions for a specific outcome type with:\n",
    "      1) Single-threshold metrics at each recall target\n",
    "      2) Multiple threshold metrics (fixed probability cutoffs)\n",
    "      3) Decision Curve Analysis\n",
    "      4) Top-k fraction approach\n",
    "    \"\"\"\n",
    "    # Filter data for the specific outcome type\n",
    "    outcome_df = df[df[\"outcome_type\"] == outcome_type].copy()\n",
    "    labels = outcome_df[\"label\"].values.astype(float)\n",
    "    probs = outcome_df[\"prob\"].values\n",
    "\n",
    "    # (1) Multiple Recalls\n",
    "    multi_recalls_df = analyze_multiple_recalls(\n",
    "        labels, probs, recall_targets=recall_targets\n",
    "    )\n",
    "\n",
    "    # We also show single-threshold metrics for the first target_recall in that list\n",
    "    target_recall = recall_targets[1]\n",
    "    threshold = find_threshold_for_recall(probs, labels, target_recall)\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    single_thr_metrics = calculate_metrics(labels, preds, probs)\n",
    "    single_thr_metrics[\"Threshold\"] = threshold\n",
    "\n",
    "    # (2) Evaluate multiple probability thresholds\n",
    "    multi_thr_df = evaluate_multiple_thresholds(labels, probs)\n",
    "\n",
    "    # (3) Decision Curve Analysis\n",
    "    dca_df = decision_curve_analysis(labels, probs, thresholds=np.linspace(0, 1, 21))\n",
    "\n",
    "    #     # (4) Top-k fraction approach (example: top 5%)\n",
    "    #     top_fraction_results = evaluate_top_k(labels, probs, fraction=0.05)\n",
    "\n",
    "    # Add predictions & misclassification for final DataFrame\n",
    "    outcome_df[\"prediction\"] = preds\n",
    "    outcome_df[\"threshold_used\"] = threshold\n",
    "    outcome_df[\"misclassified\"] = outcome_df[\"prediction\"] != outcome_df[\"label\"]\n",
    "    outcome_df[\"year_type\"] = year_type\n",
    "\n",
    "    ###########################################\n",
    "    # Print out the key results\n",
    "    ###########################################\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Results for {outcome_type} - {year_type}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Print multi-recall results\n",
    "    print(\"\\n--- Multiple Recall Targets ---\")\n",
    "    print(multi_recalls_df.round(4).to_string(index=False))\n",
    "\n",
    "    # Print single threshold metrics at the first recall target\n",
    "    print(f\"\\nSingle Threshold for {target_recall*100:.1f}% recall:\")\n",
    "    print(f\"Found threshold = {threshold:.4f}\")\n",
    "    for cat_name, cat_vals in single_thr_metrics.items():\n",
    "        if isinstance(cat_vals, dict):\n",
    "            print(f\"\\n{cat_name}:\")\n",
    "            print(\"-\" * 30)\n",
    "            for metric_name, value in cat_vals.items():\n",
    "                print(f\"{metric_name:<25} {value:.4f}\")\n",
    "        elif isinstance(cat_vals, float):\n",
    "            pass\n",
    "\n",
    "    print(\"\\n--- Multiple Operating Thresholds (Fixed Probability) ---\")\n",
    "    print(multi_thr_df.round(4).to_string(index=False))\n",
    "\n",
    "    print(\"\\n--- Decision Curve Analysis ---\")\n",
    "    print(\n",
    "        dca_df[\n",
    "            [\n",
    "                \"threshold\",\n",
    "                \"net_benefit_model\",\n",
    "                \"net_benefit_treat_all\",\n",
    "                \"net_benefit_treat_none\",\n",
    "            ]\n",
    "        ]\n",
    "        .round(4)\n",
    "        .to_string(index=False)\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Top-Fraction Approach (e.g., Top 5%) ---\")\n",
    "    for k, v in evaluate_top_k(labels, probs, fraction=0.05).items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"{k:<20}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"{k:<20}: {v}\")\n",
    "\n",
    "    print(\"\\n--- Top-Fraction Approach (e.g., Top 10%) ---\")\n",
    "    for k, v in evaluate_top_k(labels, probs, fraction=0.10).items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"{k:<20}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"{k:<20}: {v}\")\n",
    "\n",
    "    print(\"\\n--- Top-Fraction Approach (e.g., Top 20%) ---\")\n",
    "    for k, v in evaluate_top_k(labels, probs, fraction=0.20).items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"{k:<20}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"{k:<20}: {v}\")\n",
    "\n",
    "    return outcome_df, single_thr_metrics, multi_recalls_df, multi_thr_df, dca_df, _\n",
    "\n",
    "\n",
    "def analyze_all_outcomes(df, year_type, recall_targets=[0.5, 0.6, 0.7, 0.8, 0.9]):\n",
    "    \"\"\"\n",
    "    Analyze predictions for all outcome types with comprehensive metrics.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    all_metrics = {}\n",
    "    for outcome in df[\"outcome_type\"].unique():\n",
    "        (\n",
    "            outcome_results,\n",
    "            single_thr_metrics,\n",
    "            multi_recalls_df,\n",
    "            multi_thr_df,\n",
    "            dca_df,\n",
    "            top_k_dict,\n",
    "        ) = analyze_predictions(df, outcome, year_type, recall_targets=recall_targets)\n",
    "\n",
    "        all_results.append(outcome_results)\n",
    "        # Store as you wish\n",
    "        all_metrics[outcome] = {\n",
    "            \"SingleThrMetrics\": single_thr_metrics,\n",
    "            \"MultiRecallsDF\": multi_recalls_df,\n",
    "            \"MultiThreshDF\": multi_thr_df,\n",
    "            \"DecisionCurveDF\": dca_df,\n",
    "            \"TopFractionResults\": top_k_dict,\n",
    "        }\n",
    "\n",
    "    return pd.concat(all_results), all_metrics\n",
    "\n",
    "\n",
    "#######################################\n",
    "# EXAMPLE USAGE\n",
    "#######################################\n",
    "\n",
    "model_name = \"LGBM\"\n",
    "dataset = \"real777\"\n",
    "\n",
    "# Load your predictions\n",
    "all_predictions = pd.read_csv(\n",
    "    f\"{dataset}/results/next_year_prediction_results_{model_name}_multi_year_training_best_model_calibrated.csv\",\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "# Decide whether to use calibrated or uncalibrated probabilities\n",
    "all_predictions[\"prob\"] = all_predictions[\"uncali_prob\"]\n",
    "# all_predictions[\"prob\"] = all_predictions[\"cali_prob_full\"]\n",
    "\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# We analyze \"death\" and \"graft_loss\" separately, for \"Y1\" vs \"Y2+\"\n",
    "for outcome_type in [\"death\", \"graft_loss\"]:\n",
    "    for y_type in [\"Y1\", \"Y2+\"]:\n",
    "        if y_type == \"Y1\":\n",
    "            sub_predictions = all_predictions.loc[\n",
    "                (all_predictions[\"outcome_type\"] == outcome_type)\n",
    "                & (all_predictions[\"year\"] == 0)\n",
    "            ]\n",
    "        else:\n",
    "            sub_predictions = all_predictions.loc[\n",
    "                (all_predictions[\"outcome_type\"] == outcome_type)\n",
    "                & (all_predictions[\"year\"] > 0)\n",
    "            ]\n",
    "        if len(sub_predictions) == 0:\n",
    "            continue\n",
    "\n",
    "        # Analyze across multiple recall targets: 50%, 60%, 70%, 80%, 90%\n",
    "        results_df, metrics_dict = analyze_all_outcomes(\n",
    "            sub_predictions, year_type=y_type, recall_targets=[0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "        )\n",
    "        all_results = pd.concat([all_results, results_df])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "TransferLearning",
   "language": "python",
   "name": "transferlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
